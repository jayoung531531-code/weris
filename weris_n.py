#!/usr/bin/env python
# coding: utf-8

# In[1]:


# ê¸°ì¡´ì˜ pip ì„¤ì¹˜ ë¶€ë¶„ì€ ê·¸ëŒ€ë¡œ ë‘¡ë‹ˆë‹¤.
get_ipython().system('pip install pandas')
get_ipython().system('pip install scikit-learn')
get_ipython().system('pip install requests')

import pandas as pd
import numpy as np
from sklearn.neighbors import KNeighborsClassifier
import requests
import pickle

# 'transposed_data.csv' íŒŒì¼ì„ ì½ê³ , 'abc' ì—´ì„ ì¸ë±ìŠ¤ë¡œ ì„¤ì •í•©ë‹ˆë‹¤.
try:
    df = pd.read_csv('transposed_data.csv', index_col='abc')
except FileNotFoundError:
    print("ì˜¤ë¥˜: transposed_data.csv íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. íŒŒì¼ ê²½ë¡œë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”.")
    exit()

# ë°ì´í„° ì „ì²˜ë¦¬: ê²°ì¸¡ì¹˜ ì œê±°
df_cleaned = df.dropna(axis=1)

# ğŸ’¡ ì¦ìƒ ë°ì´í„° íŒŒì¼ì„ í•œ ë²ˆì— ë¡œë“œí•˜ì§€ ì•ŠìŠµë‹ˆë‹¤. ğŸ’¡
# data1, data2, data3 ë³€ìˆ˜ ì„ ì–¸ ë¶€ë¶„ì„ ì œê±°í•˜ê³ , í•„ìš”í•œ ì‹œì ì— chunkë¡œ ì½ìŠµë‹ˆë‹¤.

# ğŸ’¡ APIë¡œë¶€í„° ë°ì´í„°ë¥¼ ê°€ì ¸ì˜¤ëŠ” í•¨ìˆ˜ (ìˆœìˆ˜ API ì—°ë™) ğŸ’¡
def get_data_from_api():
    """
    APIë¡œë¶€í„° ì¦ìƒ ë° ì£¼ì°¨ ë°ì´í„°ë¥¼ ë°›ì•„ì˜¤ëŠ” ì—­í• ì„ í•©ë‹ˆë‹¤.
    """
    API_FETCH_URL = 'http://api.example.com/symptoms_and_week'
    try:
        response = requests.get(API_FETCH_URL)
        response.raise_for_status()
        api_data = response.json()
        symptom_data = api_data.get('symptoms')
        week = api_data.get('week')
        if not symptom_data or not week:
            print("API ì‘ë‹µì— 'symptoms' ë˜ëŠ” 'week' ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return None, None
        return symptom_data, week
    except requests.exceptions.RequestException as e:
        print(f"API í˜¸ì¶œ ì˜¤ë¥˜: {e}")
        return None, None

# =========================================================================
# ğŸ’¡ API ì—°ë™ í•¨ìˆ˜ë¥¼ í˜¸ì¶œí•˜ì—¬ ë°ì´í„° ê°€ì ¸ì˜¤ê¸° ğŸ’¡
# =========================================================================

symptom_data, week = get_data_from_api()

if symptom_data is None or week is None:
    print("APIë¡œë¶€í„° ë°ì´í„°ê°€ ë“¤ì–´ì˜¤ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
    exit()

print(f"\nAPIë¡œë¶€í„° ë°›ì€ ì£¼ì°¨: {week}")
print(f"APIë¡œë¶€í„° ë°›ì€ ì¦ìƒ ë°ì´í„°: {symptom_data}")

# =========================================================================
# ìŠ¤íŠ¸ë ˆìŠ¤ ì§€ìˆ˜ ê³„ì‚° (ë©”ëª¨ë¦¬ ìµœì í™”)
# =========================================================================
file_paths = ['data1.csv', 'data2.csv', 'data3.csv']
scores = []

for file_path in file_paths:
    score = 0
    # chunksizeë¥¼ 1000ìœ¼ë¡œ ì„¤ì •í•˜ì—¬ 1000ì¤„ì”© ì½ìŠµë‹ˆë‹¤.
    # íŒŒì¼ í¬ê¸°ì— ë”°ë¼ ì´ ê°’ì„ ì¡°ì •í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
    try:
        chunk_reader = pd.read_csv(file_path, chunksize=1000)
        for chunk in chunk_reader:
            for col, user_val in symptom_data.items():
                if col in chunk.columns:
                    csv_val = chunk[col].iloc[0]
                    if user_val is True:
                        score += 1.3 if csv_val == 1 else 0.8
                    elif user_val is False:
                        score += 0.3 if csv_val == 1 else 0.0
    except FileNotFoundError:
        print(f"ì˜¤ë¥˜: {file_path} íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ê±´ë„ˆëœë‹ˆë‹¤.")
        continue
    except KeyError:
        print(f"ì˜¤ë¥˜: {file_path} íŒŒì¼ì— í•„ìš”í•œ ì—´ì´ ì—†ìŠµë‹ˆë‹¤. ê±´ë„ˆëœë‹ˆë‹¤.")
        continue
    scores.append(score)

# ëª¨ë“  íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠëŠ” ê²½ìš°ë¥¼ ëŒ€ë¹„
if not scores:
    print("ê³„ì‚°í•  ìœ íš¨í•œ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. í”„ë¡œê·¸ë¨ì„ ì¢…ë£Œí•©ë‹ˆë‹¤.")
    exit()
    
stress_level = min(np.mean(scores), 10)
print(f"\nê³„ì‚°ëœ ìŠ¤íŠ¸ë ˆìŠ¤ ì§€ìˆ˜: {stress_level:.2f}")

# =========================================================================
# ğŸ¤– ë¨¸ì‹ ëŸ¬ë‹ ëª¨ë¸: KNN ë¶„ë¥˜ê¸° ğŸ¤–
# =========================================================================
model_filename = 'knn_model.pkl'

try:
    with open(model_filename, 'rb') as file:
        model = pickle.load(file)
    print(f"\n'{model_filename}' íŒŒì¼ì—ì„œ ëª¨ë¸ì„ ì„±ê³µì ìœ¼ë¡œ ë¶ˆëŸ¬ì™”ìŠµë‹ˆë‹¤.")
except FileNotFoundError:
    print(f"\n'{model_filename}' íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ìƒˆë¡œìš´ ëª¨ë¸ì„ í•™ìŠµí•˜ê³  ì €ì¥í•©ë‹ˆë‹¤.")
    X_train = np.array([
        [1, 5.2], [2, 3.8], [3, 7.5], [4, 6.1], [5, 9.0], [6, 4.5]
    ])
    y_train = np.array(['A', 'A', 'B', 'B', 'C', 'C'])
    model = KNeighborsClassifier(n_neighbors=1)
    model.fit(X_train, y_train)
    with open(model_filename, 'wb') as file:
        pickle.dump(model, file)
    print(f"ìƒˆë¡œìš´ ëª¨ë¸ì´ '{model_filename}' íŒŒì¼ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")

# 3. ì˜ˆì¸¡í•  ìƒˆë¡œìš´ ë°ì´í„° í¬ì¸íŠ¸ ì¤€ë¹„
new_data_point = np.array([[week, stress_level]])

# 4. ëª¨ë¸ì„ ì‚¬ìš©í•˜ì—¬ ì˜ˆì¸¡
prediction = model.predict(new_data_point)

print(f"\nì…ë ¥í•˜ì‹  ë°ì´í„°ëŠ” '{prediction[0]}' ê·¸ë£¹ì— ê°€ì¥ ê°€ê¹ìŠµë‹ˆë‹¤.")

# =========================================================================
# ğŸ’¡ ì¶œë ¥ ê°’ì„ APIë¡œ ì „ì†¡í•˜ëŠ” ë¶€ë¶„ ğŸ’¡
# =========================================================================
API_URL = 'http://api.example.com/results'

payload = {
    'stress_level': float(f"{stress_level:.2f}"),
    'prediction': prediction[0],
    'week': week
}

print(f"\nAPIë¡œ ì „ì†¡í•  ë°ì´í„°: {payload}")

try:
    response = requests.post(API_URL, json=payload)
    if response.status_code == 200:
        print("\nâœ… ë°ì´í„° ì „ì†¡ ì„±ê³µ!")
        print(f"ì„œë²„ ì‘ë‹µ: {response.json()}")
    else:
        print(f"\nâŒ ë°ì´í„° ì „ì†¡ ì‹¤íŒ¨! ìƒíƒœ ì½”ë“œ: {response.status_code}")
        print(f"ì„œë²„ ì‘ë‹µ: {response.text}")
except requests.exceptions.RequestException as e:
    print(f"\nâš ï¸ API í†µì‹  ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")


# In[ ]:




